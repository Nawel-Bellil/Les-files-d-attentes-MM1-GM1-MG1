{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2iIo2n/5f6HN43F5YZ2Ym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawel-Bellil/Les-files-d-attentes-MM1-GM1-MG1/blob/main/code/mg1_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ucYmW2-_UoZL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class MG1Simulator:\n",
        "    \"\"\"\n",
        "    M/G/1 Queue Simulator\n",
        "    - M: Poisson arrivals (exponential inter-arrival times)\n",
        "    - G: General service time distribution (Gamma distribution)\n",
        "    - 1: Single server\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambda_rate, mu_rate, shape=2.0, num_customers=2000000, seed=42):\n",
        "        \"\"\"\n",
        "        Initialize M/G/1 simulator\n",
        "\n",
        "        Args:\n",
        "            lambda_rate (float): Arrival rate (λ)\n",
        "            mu_rate (float): Service rate (μ)\n",
        "            shape (float): Shape parameter for Gamma distribution\n",
        "            num_customers (int): Number of customers to simulate\n",
        "            seed (int): Random seed\n",
        "        \"\"\"\n",
        "        if lambda_rate <= 0 or mu_rate <= 0:\n",
        "            raise ValueError(\"Arrival and service rates must be positive\")\n",
        "        if lambda_rate >= mu_rate:\n",
        "            print(f\"Warning: λ={lambda_rate} >= μ={mu_rate}, system may be unstable\")\n",
        "\n",
        "        self.lambda_rate = lambda_rate\n",
        "        self.mu_rate = mu_rate\n",
        "        self.shape = shape\n",
        "        self.num_customers = num_customers\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "\n",
        "        # Gamma scale parameter: E[S] = shape * scale = 1/μ\n",
        "        self.scale = 1.0 / (mu_rate * shape)\n",
        "\n",
        "        # Results storage\n",
        "        self.waiting_times = np.zeros(num_customers)\n",
        "        self.response_times = np.zeros(num_customers)\n",
        "        self.service_times = np.zeros(num_customers)\n",
        "        self.server_busy_time = 0\n",
        "        self.total_simulation_time = 0\n",
        "\n",
        "    def generate_interarrival_time(self):\n",
        "        \"\"\"Generate exponential inter-arrival time\"\"\"\n",
        "        return self.rng.exponential(scale=1/self.lambda_rate)\n",
        "\n",
        "    def generate_service_time(self):\n",
        "        \"\"\"Generate Gamma service time\"\"\"\n",
        "        return self.rng.gamma(shape=self.shape, scale=self.scale)\n",
        "\n",
        "    def run_simulation(self):\n",
        "        \"\"\"Run the M/G/1 simulation using event-driven approach\"\"\"\n",
        "        print(f\"Starting M/G/1 simulation with {self.num_customers} customers...\")\n",
        "\n",
        "        # Generate all inter-arrival times\n",
        "        inter_arrival_times = np.array([self.generate_interarrival_time()\n",
        "                                      for _ in range(self.num_customers)])\n",
        "\n",
        "        # Generate all service times\n",
        "        service_times = np.array([self.generate_service_time()\n",
        "                                for _ in range(self.num_customers)])\n",
        "\n",
        "        # Calculate arrival times\n",
        "        arrival_times = np.cumsum(inter_arrival_times)\n",
        "\n",
        "        # Initialize simulation\n",
        "        departure_times = np.zeros(self.num_customers)\n",
        "        current_departure_time = 0\n",
        "\n",
        "        print(\"Processing customers...\")\n",
        "        for i in tqdm(range(self.num_customers)):\n",
        "            arrival_time = arrival_times[i]\n",
        "            service_time = service_times[i]\n",
        "\n",
        "            # Calculate waiting time and departure time\n",
        "            if arrival_time >= current_departure_time:\n",
        "                # Server is free\n",
        "                waiting_time = 0\n",
        "                departure_time = arrival_time + service_time\n",
        "            else:\n",
        "                # Server is busy, customer must wait\n",
        "                waiting_time = current_departure_time - arrival_time\n",
        "                departure_time = current_departure_time + service_time\n",
        "\n",
        "            # Update current departure time\n",
        "            current_departure_time = departure_time\n",
        "\n",
        "            # Store results\n",
        "            self.waiting_times[i] = waiting_time\n",
        "            self.service_times[i] = service_time\n",
        "            self.response_times[i] = waiting_time + service_time\n",
        "            departure_times[i] = departure_time\n",
        "\n",
        "        # Calculate total simulation time and server busy time\n",
        "        self.total_simulation_time = departure_times[-1]\n",
        "        self.server_busy_time = np.sum(service_times)\n",
        "\n",
        "        # Calculate metrics\n",
        "        self.calculate_metrics()\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "        \"\"\"Calculate simulation metrics\"\"\"\n",
        "        self.avg_waiting_time = np.mean(self.waiting_times)\n",
        "        self.avg_response_time = np.mean(self.response_times)\n",
        "        self.avg_service_time = np.mean(self.service_times)\n",
        "        self.server_utilization = self.server_busy_time / self.total_simulation_time\n",
        "\n",
        "        # System length metrics (Little's Law: L = λW)\n",
        "        self.avg_system_length = self.lambda_rate * self.avg_response_time\n",
        "        self.avg_queue_length = self.lambda_rate * self.avg_waiting_time\n",
        "\n",
        "        # Additional metrics\n",
        "        self.max_waiting_time = np.max(self.waiting_times)\n",
        "        self.std_waiting_time = np.std(self.waiting_times)\n",
        "        self.waiting_time_95th = np.percentile(self.waiting_times, 95)\n",
        "\n",
        "    def get_theoretical_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate theoretical M/G/1 metrics using Pollaczek-Khinchine formula\n",
        "\n",
        "        For M/G/1 with Gamma service times:\n",
        "        - E[S] = 1/μ\n",
        "        - Var[S] = shape * scale²\n",
        "        - ρ = λ/μ\n",
        "        - E[W] = λ * (E[S²]) / (2 * (1 - ρ))\n",
        "        - E[T] = E[W] + E[S]\n",
        "        - L = λ * E[T] (Little's Law)\n",
        "        \"\"\"\n",
        "        rho = self.lambda_rate / self.mu_rate\n",
        "\n",
        "        if rho >= 1:\n",
        "            return {\n",
        "                'rho': rho,\n",
        "                'avg_waiting_time': float('inf'),\n",
        "                'avg_response_time': float('inf'),\n",
        "                'avg_queue_length': float('inf'),\n",
        "                'avg_system_length': float('inf'),\n",
        "                'stable': False\n",
        "            }\n",
        "\n",
        "        # Service time moments for Gamma distribution\n",
        "        mean_service = 1 / self.mu_rate\n",
        "        var_service = self.shape * self.scale**2\n",
        "        second_moment_service = var_service + mean_service**2\n",
        "\n",
        "        # Pollaczek-Khinchine formula\n",
        "        avg_waiting_time = (self.lambda_rate * second_moment_service) / (2 * (1 - rho))\n",
        "        avg_response_time = avg_waiting_time + mean_service\n",
        "        avg_queue_length = self.lambda_rate * avg_waiting_time\n",
        "        avg_system_length = self.lambda_rate * avg_response_time\n",
        "\n",
        "        return {\n",
        "            'rho': rho,\n",
        "            'avg_waiting_time': avg_waiting_time,\n",
        "            'avg_response_time': avg_response_time,\n",
        "            'avg_queue_length': avg_queue_length,\n",
        "            'avg_system_length': avg_system_length,\n",
        "            'avg_service_time': mean_service,\n",
        "            'var_service_time': var_service,\n",
        "            'stable': True\n",
        "        }\n",
        "\n",
        "    def get_results(self):\n",
        "        \"\"\"Get simulation results as dictionary\"\"\"\n",
        "        theoretical = self.get_theoretical_metrics()\n",
        "\n",
        "        return {\n",
        "            'lambda': self.lambda_rate,\n",
        "            'mu': self.mu_rate,\n",
        "            'rho': self.lambda_rate / self.mu_rate,\n",
        "            'avg_response_time_emp': self.avg_response_time,\n",
        "            'avg_response_time_theo': theoretical['avg_response_time'],\n",
        "            'avg_waiting_time_emp': self.avg_waiting_time,\n",
        "            'avg_waiting_time_theo': theoretical['avg_waiting_time'],\n",
        "            'server_utilization_emp': self.server_utilization,\n",
        "            'server_utilization_theo': theoretical['rho'],\n",
        "            'avg_system_length_theo': theoretical['avg_system_length'],\n",
        "            'avg_system_length_emp': self.avg_system_length,\n",
        "            'customers_served': self.num_customers,\n",
        "            'simulation_time': self.total_simulation_time,\n",
        "            'avg_service_time': self.avg_service_time,\n",
        "            'shape_parameter': self.shape\n",
        "        }\n"
      ],
      "metadata": {
        "id": "HF-OhJvsUt8t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_mg1_experiments(lambda_values, mu=1.0, shape=2.0, num_customers=2000000):\n",
        "    \"\"\"\n",
        "    Run M/G/1 experiments for different arrival rates\n",
        "\n",
        "    Args:\n",
        "        lambda_values: List of arrival rates to test\n",
        "        mu: Service rate\n",
        "        shape: Gamma shape parameter\n",
        "        num_customers: Number of customers per simulation\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(f\"\\nRunning M/G/1 experiments\")\n",
        "    print(f\"Lambda values: {lambda_values}\")\n",
        "    print(f\"μ = {mu}, shape = {shape}, customers = {num_customers}\")\n",
        "\n",
        "    for lambda_val in tqdm(lambda_values, desc=\"M/G/1 Experiments\"):\n",
        "        if lambda_val >= mu:\n",
        "            print(f\"Skipping λ={lambda_val} >= μ={mu} (unstable)\")\n",
        "            continue\n",
        "\n",
        "        simulator = MG1Simulator(lambda_val, mu, shape, num_customers)\n",
        "        simulator.run_simulation()\n",
        "        results.append(simulator.get_results())\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "Gb13GmZAUwc_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_different_shapes(lambda_values, shapes, mu=1.0, num_customers=500000):\n",
        "    \"\"\"\n",
        "    Compare M/G/1 performance for different Gamma shape parameters\n",
        "\n",
        "    Args:\n",
        "        lambda_values: List of arrival rates to test\n",
        "        shapes: List of Gamma shape parameters to test\n",
        "        mu: Service rate\n",
        "        num_customers: Number of customers per simulation\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results for each shape\n",
        "    \"\"\"\n",
        "    results_by_shape = {}\n",
        "\n",
        "    print(f\"\\nComparing different Gamma shapes: {shapes}\")\n",
        "\n",
        "    for shape in tqdm(shapes, desc=\"Shape Comparison\"):\n",
        "        print(f\"\\nTesting shape = {shape}\")\n",
        "        results = run_mg1_experiments(lambda_values, mu, shape, num_customers)\n",
        "        results_by_shape[shape] = results\n",
        "\n",
        "    return results_by_shape\n"
      ],
      "metadata": {
        "id": "PKnbumFeUynA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_mg1_comparison(results):\n",
        "    \"\"\"\n",
        "    Plot comprehensive empirical vs theoretical comparison for M/G/1\n",
        "\n",
        "    Args:\n",
        "        results: DataFrame with simulation results\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "\n",
        "    # Response time comparison\n",
        "    axes[0,0].plot(results['rho'], results['avg_response_time_emp'],\n",
        "                   'o-', label='Empirical', linewidth=2, markersize=8, color='blue')\n",
        "    axes[0,0].plot(results['rho'], results['avg_response_time_theo'],\n",
        "                   '--', label='Theoretical', linewidth=2, color='red')\n",
        "    axes[0,0].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[0,0].set_ylabel('Average Response Time')\n",
        "    axes[0,0].set_title('Average Response Time vs ρ')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Waiting time comparison\n",
        "    axes[0,1].plot(results['rho'], results['avg_waiting_time_emp'],\n",
        "                   'o-', label='Empirical', linewidth=2, markersize=8, color='green')\n",
        "    axes[0,1].plot(results['rho'], results['avg_waiting_time_theo'],\n",
        "                   '--', label='Theoretical', linewidth=2, color='red')\n",
        "    axes[0,1].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[0,1].set_ylabel('Average Waiting Time')\n",
        "    axes[0,1].set_title('Average Waiting Time vs ρ')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Server utilization comparison\n",
        "    axes[0,2].plot(results['rho'], results['server_utilization_emp'],\n",
        "                   'o-', label='Empirical', linewidth=2, markersize=8, color='purple')\n",
        "    axes[0,2].plot(results['rho'], results['server_utilization_theo'],\n",
        "                   '--', label='Theoretical', linewidth=2, color='red')\n",
        "    axes[0,2].set_xlabel('Theoretical Utilization (ρ)')\n",
        "    axes[0,2].set_ylabel('Measured Utilization')\n",
        "    axes[0,2].set_title('Server Utilization Validation')\n",
        "    axes[0,2].legend()\n",
        "    axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "    # System length comparison\n",
        "    axes[1,0].plot(results['rho'], results['avg_system_length_emp'],\n",
        "                   'o-', label='Empirical', linewidth=2, markersize=8, color='cyan')\n",
        "    axes[1,0].plot(results['rho'], results['avg_system_length_theo'],\n",
        "                   '--', label='Theoretical', linewidth=2, color='red')\n",
        "    axes[1,0].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[1,0].set_ylabel('Average System Length')\n",
        "    axes[1,0].set_title('Average System Length vs ρ')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Response time vs lambda\n",
        "    axes[1,1].plot(results['lambda'], results['avg_response_time_emp'],\n",
        "                   'o-', label='Empirical', linewidth=2, markersize=8, color='orange')\n",
        "    axes[1,1].plot(results['lambda'], results['avg_response_time_theo'],\n",
        "                   '--', label='Theoretical', linewidth=2, color='red')\n",
        "    axes[1,1].set_xlabel('Arrival Rate (λ)')\n",
        "    axes[1,1].set_ylabel('Average Response Time')\n",
        "    axes[1,1].set_title('Response Time vs Arrival Rate')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Error analysis\n",
        "    response_error = abs(results['avg_response_time_emp'] - results['avg_response_time_theo']) / results['avg_response_time_theo'] * 100\n",
        "    waiting_error = abs(results['avg_waiting_time_emp'] - results['avg_waiting_time_theo']) / results['avg_waiting_time_theo'] * 100\n",
        "    system_error = abs(results['avg_system_length_emp'] - results['avg_system_length_theo']) / results['avg_system_length_theo'] * 100\n",
        "\n",
        "    axes[1,2].plot(results['rho'], response_error, 'o-', label='Response Time Error',\n",
        "                   linewidth=2, markersize=8, color='red')\n",
        "    axes[1,2].plot(results['rho'], waiting_error, 's-', label='Waiting Time Error',\n",
        "                   linewidth=2, markersize=8, color='blue')\n",
        "    axes[1,2].plot(results['rho'], system_error, '^-', label='System Length Error',\n",
        "                   linewidth=2, markersize=8, color='green')\n",
        "    axes[1,2].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[1,2].set_ylabel('Relative Error (%)')\n",
        "    axes[1,2].set_title('Simulation Error Analysis')\n",
        "    axes[1,2].legend()\n",
        "    axes[1,2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('M/G/1 Simulation: Comprehensive Empirical vs Theoretical Analysis', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "y_kfrqUOU1q7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_shape_comparison(results_by_shape):\n",
        "    \"\"\"Plot comprehensive comparison of different Gamma shapes\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    colors = ['blue', 'red', 'green', 'purple', 'orange']\n",
        "    markers = ['o', 's', '^', 'D', 'v']\n",
        "\n",
        "    for i, (shape, results) in enumerate(results_by_shape.items()):\n",
        "        color = colors[i % len(colors)]\n",
        "        marker = markers[i % len(markers)]\n",
        "\n",
        "        # Response time vs rho (empirical)\n",
        "        axes[0,0].plot(results['rho'], results['avg_response_time_emp'],\n",
        "                      marker=marker, linestyle='-', label=f'Shape = {shape}',\n",
        "                      color=color, linewidth=2, markersize=6)\n",
        "\n",
        "        # Response time vs rho (theoretical)\n",
        "        axes[0,1].plot(results['rho'], results['avg_response_time_theo'],\n",
        "                      marker=marker, linestyle='--', label=f'Shape = {shape}',\n",
        "                      color=color, linewidth=2, markersize=6)\n",
        "\n",
        "        # Waiting time vs rho (empirical)\n",
        "        axes[1,0].plot(results['rho'], results['avg_waiting_time_emp'],\n",
        "                      marker=marker, linestyle='-', label=f'Shape = {shape}',\n",
        "                      color=color, linewidth=2, markersize=6)\n",
        "\n",
        "        # Waiting time vs rho (theoretical)\n",
        "        axes[1,1].plot(results['rho'], results['avg_waiting_time_theo'],\n",
        "                      marker=marker, linestyle='--', label=f'Shape = {shape}',\n",
        "                      color=color, linewidth=2, markersize=6)\n",
        "\n",
        "    axes[0,0].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[0,0].set_ylabel('Average Response Time')\n",
        "    axes[0,0].set_title('Empirical Response Time vs ρ')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[0,1].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[0,1].set_ylabel('Average Response Time')\n",
        "    axes[0,1].set_title('Theoretical Response Time vs ρ')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1,0].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[1,0].set_ylabel('Average Waiting Time')\n",
        "    axes[1,0].set_title('Empirical Waiting Time vs ρ')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1,1].set_xlabel('Server Utilization (ρ)')\n",
        "    axes[1,1].set_ylabel('Average Waiting Time')\n",
        "    axes[1,1].set_title('Theoretical Waiting Time vs ρ')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('M/G/1: Impact of Service Time Variability (Gamma Shape Parameters)', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "GYi9_khSU4cV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_coefficient_variation_analysis(results_by_shape):\n",
        "    \"\"\"\n",
        "    Plot analysis showing the impact of coefficient of variation\n",
        "    CV = σ/μ = 1/√shape for Gamma distribution\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Calculate coefficient of variation for each shape\n",
        "    cv_values = {shape: 1/np.sqrt(shape) for shape in results_by_shape.keys()}\n",
        "\n",
        "    colors = ['blue', 'red', 'green', 'purple', 'orange']\n",
        "\n",
        "    # For a fixed rho, show how response time varies with CV\n",
        "    rho_target = 0.7\n",
        "    response_times_emp = []\n",
        "    response_times_theo = []\n",
        "    waiting_times_emp = []\n",
        "    waiting_times_theo = []\n",
        "    cv_list = []\n",
        "    shape_list = []\n",
        "\n",
        "    for shape, results in results_by_shape.items():\n",
        "        # Find closest rho to target\n",
        "        closest_idx = np.argmin(np.abs(results['rho'] - rho_target))\n",
        "        if np.abs(results['rho'].iloc[closest_idx] - rho_target) < 0.05:  # Within 5%\n",
        "            response_times_emp.append(results['avg_response_time_emp'].iloc[closest_idx])\n",
        "            response_times_theo.append(results['avg_response_time_theo'].iloc[closest_idx])\n",
        "            waiting_times_emp.append(results['avg_waiting_time_emp'].iloc[closest_idx])\n",
        "            waiting_times_theo.append(results['avg_waiting_time_theo'].iloc[closest_idx])\n",
        "            cv_list.append(cv_values[shape])\n",
        "            shape_list.append(shape)\n",
        "\n",
        "    # Response time vs CV\n",
        "    axes[0].plot(cv_list, response_times_emp, 'o-', label='Empirical',\n",
        "                linewidth=2, markersize=8, color='blue')\n",
        "    axes[0].plot(cv_list, response_times_theo, 's--', label='Theoretical',\n",
        "                linewidth=2, markersize=8, color='red')\n",
        "    axes[0].set_xlabel('Coefficient of Variation (CV)')\n",
        "    axes[0].set_ylabel('Average Response Time')\n",
        "    axes[0].set_title(f'Response Time vs Service Variability (ρ≈{rho_target})')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Waiting time vs CV\n",
        "    axes[1].plot(cv_list, waiting_times_emp, 'o-', label='Empirical',\n",
        "                linewidth=2, markersize=8, color='green')\n",
        "    axes[1].plot(cv_list, waiting_times_theo, 's--', label='Theoretical',\n",
        "                linewidth=2, markersize=8, color='red')\n",
        "    axes[1].set_xlabel('Coefficient of Variation (CV)')\n",
        "    axes[1].set_ylabel('Average Waiting Time')\n",
        "    axes[1].set_title(f'Waiting Time vs Service Variability (ρ≈{rho_target})')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Show CV values for each shape\n",
        "    shapes_for_plot = list(results_by_shape.keys())\n",
        "    cvs_for_plot = [cv_values[shape] for shape in shapes_for_plot]\n",
        "    axes[2].bar(range(len(shapes_for_plot)), cvs_for_plot,\n",
        "               color=['blue', 'red', 'green', 'purple', 'orange'][:len(shapes_for_plot)])\n",
        "    axes[2].set_xlabel('Gamma Shape Parameter')\n",
        "    axes[2].set_ylabel('Coefficient of Variation')\n",
        "    axes[2].set_title('CV = σ/μ = 1/√shape')\n",
        "    axes[2].set_xticks(range(len(shapes_for_plot)))\n",
        "    axes[2].set_xticklabels([f'{shape}' for shape in shapes_for_plot])\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Add CV values as text on bars\n",
        "    for i, (shape, cv) in enumerate(zip(shapes_for_plot, cvs_for_plot)):\n",
        "        axes[2].text(i, cv + 0.05, f'{cv:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.suptitle('M/G/1: Impact of Service Time Coefficient of Variation', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "aMore_E9U7nH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_detailed_distributions(simulator, title_suffix=\"\"):\n",
        "    \"\"\"\n",
        "    Plot detailed distribution analysis for a single M/G/1 simulation\n",
        "\n",
        "    Args:\n",
        "        simulator: MG1Simulator instance after running simulation\n",
        "        title_suffix: Additional title information\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "\n",
        "    # Waiting time distribution\n",
        "    axes[0,0].hist(simulator.waiting_times[simulator.waiting_times > 0],\n",
        "                   bins=50, alpha=0.7, density=True, color='blue', edgecolor='black')\n",
        "    axes[0,0].set_xlabel('Waiting Time')\n",
        "    axes[0,0].set_ylabel('Density')\n",
        "    axes[0,0].set_title(f'Waiting Time Distribution{title_suffix}')\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Response time distribution\n",
        "    axes[0,1].hist(simulator.response_times, bins=50, alpha=0.7, density=True,\n",
        "                   color='green', edgecolor='black')\n",
        "    axes[0,1].set_xlabel('Response Time')\n",
        "    axes[0,1].set_ylabel('Density')\n",
        "    axes[0,1].set_title(f'Response Time Distribution{title_suffix}')\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Service time distribution\n",
        "    axes[0,2].hist(simulator.service_times, bins=50, alpha=0.7, density=True,\n",
        "                   color='red', edgecolor='black')\n",
        "    axes[0,2].set_xlabel('Service Time')\n",
        "    axes[0,2].set_ylabel('Density')\n",
        "    axes[0,2].set_title(f'Service Time Distribution (Gamma){title_suffix}')\n",
        "    axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Waiting time CDF\n",
        "    sorted_waiting = np.sort(simulator.waiting_times)\n",
        "    cdf_waiting = np.arange(1, len(sorted_waiting) + 1) / len(sorted_waiting)\n",
        "    axes[1,0].plot(sorted_waiting, cdf_waiting, linewidth=2, color='blue')\n",
        "    axes[1,0].set_xlabel('Waiting Time')\n",
        "    axes[1,0].set_ylabel('Cumulative Probability')\n",
        "    axes[1,0].set_title(f'Waiting Time CDF{title_suffix}')\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Response time CDF\n",
        "    sorted_response = np.sort(simulator.response_times)\n",
        "    cdf_response = np.arange(1, len(sorted_response) + 1) / len(sorted_response)\n",
        "    axes[1,1].plot(sorted_response, cdf_response, linewidth=2, color='green')\n",
        "    axes[1,1].set_xlabel('Response Time')\n",
        "    axes[1,1].set_ylabel('Cumulative Probability')\n",
        "    axes[1,1].set_title(f'Response Time CDF{title_suffix}')\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Queue evolution over time (sample)\n",
        "    sample_size = min(10000, len(simulator.waiting_times))\n",
        "    sample_indices = np.linspace(0, len(simulator.waiting_times)-1, sample_size, dtype=int)\n",
        "    axes[1,2].plot(sample_indices, simulator.waiting_times[sample_indices],\n",
        "                   alpha=0.7, color='purple')\n",
        "    axes[1,2].set_xlabel('Customer Number')\n",
        "    axes[1,2].set_ylabel('Waiting Time')\n",
        "    axes[1,2].set_title(f'Waiting Time Evolution{title_suffix}')\n",
        "    axes[1,2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(f'M/G/1 Detailed Distribution Analysis{title_suffix}', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "XR1rbzUIU-Y8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DMiJxXiOTv8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run M/G/1 simulations\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"M/G/1 QUEUE SIMULATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simulation parameters\n",
        "    lambda_values = np.arange(0.1, 0.9, 0.1)\n",
        "    mu = 1.0\n",
        "    shape = 2.0\n",
        "    num_customers = 2000000\n",
        "\n",
        "    print(f\"Parameters:\")\n",
        "    print(f\"- Arrival rates (λ): {lambda_values}\")\n",
        "    print(f\"- Service rate (μ): {mu}\")\n",
        "    print(f\"- Gamma shape: {shape}\")\n",
        "    print(f\"- Customers per simulation: {num_customers:,}\")\n",
        "\n",
        "    # Run main experiment\n",
        "    results = run_mg1_experiments(lambda_values, mu, shape, num_customers)\n",
        "\n",
        "    # Save results to CSV with requested columns\n",
        "    csv_filename = 'mg1_results.csv'\n",
        "    # Reorder columns to match requested format\n",
        "    column_order = [\n",
        "        'lambda', 'mu', 'rho', 'avg_response_time_emp', 'avg_response_time_theo',\n",
        "        'avg_waiting_time_emp', 'avg_waiting_time_theo', 'server_utilization_emp',\n",
        "        'server_utilization_theo', 'avg_system_length_theo', 'avg_system_length_emp',\n",
        "        'customers_served', 'simulation_time'\n",
        "    ]\n",
        "    results_ordered = results[column_order]\n",
        "    results_ordered.to_csv(csv_filename, index=False)\n",
        "    print(f\"\\nResults saved to: {csv_filename}\")\n",
        "\n",
        "    # Display sample results with requested columns\n",
        "    print(\"\\nSample Results:\")\n",
        "    print(results_ordered.head(8))\n",
        "\n",
        "    # Create comparison plots\n",
        "    print(\"\\nCreating comparison plots...\")\n",
        "    fig1 = plot_mg1_comparison(results)\n",
        "    plt.savefig('mg1_empirical_vs_theoretical.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Compare different shapes (with fewer customers for speed)\n",
        "    print(\"\\nComparing different Gamma shapes...\")\n",
        "    shapes_to_test = [0.5, 1.0, 2.0, 4.0]\n",
        "    lambda_subset = np.arange(0.1, 0.9, 0.2)  # Fewer points for speed\n",
        "\n",
        "    results_by_shape = compare_different_shapes(\n",
        "        lambda_subset, shapes_to_test, mu, num_customers//4\n",
        "    )\n",
        "\n",
        "    fig2 = plot_shape_comparison(results_by_shape)\n",
        "    plt.savefig('mg1_shape_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Create coefficient of variation analysis\n",
        "    fig3 = plot_coefficient_variation_analysis(results_by_shape)\n",
        "    plt.savefig('mg1_cv_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and display accuracy metrics\n",
        "    print(\"\\nAccuracy Analysis:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'λ':<4} {'ρ':<6} {'Resp Err%':<10} {'Wait Err%':<10} {'Util Err%':<10} {'Sys Len Err%':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for _, row in results.iterrows():\n",
        "        response_error = abs(row['avg_response_time_emp'] - row['avg_response_time_theo']) / row['avg_response_time_theo'] * 100\n",
        "        waiting_error = abs(row['avg_waiting_time_emp'] - row['avg_waiting_time_theo']) / row['avg_waiting_time_theo'] * 100\n",
        "        util_error = abs(row['server_utilization_emp'] - row['server_utilization_theo']) / row['server_utilization_theo'] * 100\n",
        "        sys_len_error = abs(row['avg_system_length_emp'] - row['avg_system_length_theo']) / row['avg_system_length_theo'] * 100\n",
        "        print(f\"{row['lambda']:<4.1f} {row['rho']:<6.2f} {response_error:<10.2f} {waiting_error:<10.2f} {util_error:<10.2f} {sys_len_error:<12.2f}\")\n",
        "\n",
        "    # Overall accuracy summary\n",
        "    response_errors = abs(results['avg_response_time_emp'] - results['avg_response_time_theo']) / results['avg_response_time_theo'] * 100\n",
        "    waiting_errors = abs(results['avg_waiting_time_emp'] - results['avg_waiting_time_theo']) / results['avg_waiting_time_theo'] * 100\n",
        "    util_errors = abs(results['server_utilization_emp'] - results['server_utilization_theo']) / results['server_utilization_theo'] * 100\n",
        "    sys_len_errors = abs(results['avg_system_length_emp'] - results['avg_system_length_theo']) / results['avg_system_length_theo'] * 100\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Average Errors: Resp={response_errors.mean():.2f}%, Wait={waiting_errors.mean():.2f}%, Util={util_errors.mean():.2f}%, SysLen={sys_len_errors.mean():.2f}%\")\n",
        "    print(f\"Max Errors: Resp={response_errors.max():.2f}%, Wait={waiting_errors.max():.2f}%, Util={util_errors.max():.2f}%, SysLen={sys_len_errors.max():.2f}%\")\n",
        "\n",
        "    # Run detailed analysis for one specific case\n",
        "    print(\"\\nRunning detailed analysis for λ=0.7...\")\n",
        "    detailed_sim = MG1Simulator(0.7, mu, shape, num_customers//10, seed=42)\n",
        "    detailed_sim.run_simulation()\n",
        "\n",
        "    fig4 = plot_detailed_distributions(detailed_sim, f\" (λ={detailed_sim.lambda_rate}, ρ={detailed_sim.lambda_rate/detailed_sim.mu_rate:.2f})\")\n",
        "    plt.savefig('mg1_detailed_distributions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed metrics for the specific case\n",
        "    print(f\"\\nDetailed Metrics for λ={detailed_sim.lambda_rate}:\")\n",
        "    print(f\"- Average waiting time: {detailed_sim.avg_waiting_time:.4f}\")\n",
        "    print(f\"- Average response time: {detailed_sim.avg_response_time:.4f}\")\n",
        "    print(f\"- Server utilization: {detailed_sim.server_utilization:.4f}\")\n",
        "    print(f\"- Maximum waiting time: {detailed_sim.max_waiting_time:.4f}\")\n",
        "    print(f\"- 95th percentile waiting time: {detailed_sim.waiting_time_95th:.4f}\")\n",
        "    print(f\"- Standard deviation of waiting times: {detailed_sim.std_waiting_time:.4f}\")\n",
        "\n",
        "    # Theoretical comparison for this case\n",
        "    theoretical = detailed_sim.get_theoretical_metrics()\n",
        "    print(f\"\\nTheoretical vs Empirical Comparison:\")\n",
        "    print(f\"- Waiting time: {theoretical['avg_waiting_time']:.4f} (theo) vs {detailed_sim.avg_waiting_time:.4f} (emp)\")\n",
        "    print(f\"- Response time: {theoretical['avg_response_time']:.4f} (theo) vs {detailed_sim.avg_response_time:.4f} (emp)\")\n",
        "    print(f\"- System length: {theoretical['avg_system_length']:.4f} (theo) vs {detailed_sim.avg_system_length:.4f} (emp)\")\n",
        "\n",
        "    # Print summary of shape comparison results\n",
        "    print(f\"\\nShape Comparison Summary:\")\n",
        "    print(f\"Tested shapes: {list(results_by_shape.keys())}\")\n",
        "    for shape, shape_results in results_by_shape.items():\n",
        "        cv = 1/np.sqrt(shape)\n",
        "        avg_response = shape_results['avg_response_time_emp'].mean()\n",
        "        print(f\"Shape {shape} (CV={cv:.3f}): Avg response time = {avg_response:.3f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"\\nTotal simulation time: {total_time:.2f} seconds\")\n",
        "    print(f\"Total customers simulated: {num_customers * len(lambda_values) + (num_customers//4) * len(shapes_to_test) * len(lambda_subset) + num_customers//10:,}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"M/G/1 SIMULATION COMPLETE\")\n",
        "    print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxe-w6x6TygK",
        "outputId": "ff66f10e-c272-48bd-a58e-3f7d93948626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "M/G/1 QUEUE SIMULATION\n",
            "============================================================\n",
            "Parameters:\n",
            "- Arrival rates (λ): [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8]\n",
            "- Service rate (μ): 1.0\n",
            "- Gamma shape: 2.0\n",
            "- Customers per simulation: 2,000,000\n",
            "\n",
            "Running M/G/1 experiments\n",
            "Lambda values: [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8]\n",
            "μ = 1.0, shape = 2.0, customers = 2000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rM/G/1 Experiments:   0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 59418/2000000 [00:00<00:03, 594112.58it/s]\u001b[A\n",
            "  6%|▌         | 118830/2000000 [00:00<00:03, 572107.96it/s]\u001b[A\n",
            "  9%|▉         | 176097/2000000 [00:00<00:03, 566960.09it/s]\u001b[A\n",
            " 12%|█▏        | 232819/2000000 [00:00<00:03, 538284.10it/s]\u001b[A\n",
            " 14%|█▍        | 289314/2000000 [00:00<00:03, 547456.08it/s]\u001b[A\n",
            " 17%|█▋        | 344978/2000000 [00:00<00:03, 550473.73it/s]\u001b[A\n",
            " 20%|██        | 400139/2000000 [00:00<00:03, 525371.56it/s]\u001b[A\n",
            " 23%|██▎       | 452930/2000000 [00:00<00:03, 499974.55it/s]\u001b[A\n",
            " 25%|██▌       | 503251/2000000 [00:00<00:03, 496477.67it/s]\u001b[A\n",
            " 28%|██▊       | 557002/2000000 [00:01<00:02, 508467.96it/s]\u001b[A\n",
            " 30%|███       | 608058/2000000 [00:01<00:02, 507352.83it/s]\u001b[A\n",
            " 33%|███▎      | 659905/2000000 [00:01<00:02, 510630.93it/s]\u001b[A\n",
            " 36%|███▌      | 711076/2000000 [00:01<00:02, 508450.19it/s]\u001b[A\n",
            " 38%|███▊      | 761995/2000000 [00:01<00:02, 508287.22it/s]\u001b[A\n",
            " 41%|████      | 812875/2000000 [00:01<00:02, 508421.56it/s]\u001b[A\n",
            " 43%|████▎     | 865239/2000000 [00:01<00:02, 512947.47it/s]\u001b[A\n",
            " 46%|████▌     | 917553/2000000 [00:01<00:02, 515980.28it/s]\u001b[A\n",
            " 48%|████▊     | 969174/2000000 [00:01<00:02, 498525.34it/s]\u001b[A\n",
            " 51%|█████     | 1020364/2000000 [00:01<00:01, 502424.61it/s]\u001b[A\n",
            " 54%|█████▎    | 1070767/2000000 [00:02<00:01, 502888.36it/s]\u001b[A\n",
            " 56%|█████▌    | 1123634/2000000 [00:02<00:01, 510502.21it/s]\u001b[A\n",
            " 59%|█████▉    | 1175462/2000000 [00:02<00:01, 512801.73it/s]\u001b[A\n",
            " 61%|██████▏   | 1226789/2000000 [00:02<00:01, 501568.17it/s]\u001b[A\n",
            " 64%|██████▍   | 1279925/2000000 [00:02<00:01, 509915.77it/s]\u001b[A\n",
            " 67%|██████▋   | 1331376/2000000 [00:02<00:01, 511261.68it/s]\u001b[A\n",
            " 69%|██████▉   | 1383286/2000000 [00:02<00:01, 513575.53it/s]\u001b[A\n",
            " 73%|███████▎  | 1451443/2000000 [00:02<00:00, 563596.02it/s]\u001b[A\n",
            " 77%|███████▋  | 1540313/2000000 [00:02<00:00, 660612.09it/s]\u001b[A\n",
            " 81%|████████  | 1623170/2000000 [00:02<00:00, 710804.15it/s]\u001b[A\n",
            " 86%|████████▌ | 1720508/2000000 [00:03<00:00, 789361.10it/s]\u001b[A\n",
            " 91%|█████████ | 1816058/2000000 [00:03<00:00, 839097.38it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:03<00:00, 592127.74it/s]\n",
            "M/G/1 Experiments:  12%|█▎        | 1/8 [00:07<00:55,  7.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 90457/2000000 [00:00<00:02, 904516.95it/s]\u001b[A\n",
            "  9%|▉         | 184033/2000000 [00:00<00:01, 922864.23it/s]\u001b[A\n",
            " 14%|█▍        | 276320/2000000 [00:00<00:01, 917382.43it/s]\u001b[A\n",
            " 19%|█▊        | 371743/2000000 [00:00<00:01, 931859.59it/s]\u001b[A\n",
            " 23%|██▎       | 464937/2000000 [00:00<00:01, 928969.28it/s]\u001b[A\n",
            " 28%|██▊       | 557840/2000000 [00:00<00:01, 896077.79it/s]\u001b[A\n",
            " 32%|███▏      | 649734/2000000 [00:00<00:01, 903336.86it/s]\u001b[A\n",
            " 37%|███▋      | 742664/2000000 [00:00<00:01, 911434.08it/s]\u001b[A\n",
            " 42%|████▏     | 837143/2000000 [00:00<00:01, 921711.92it/s]\u001b[A\n",
            " 46%|████▋     | 929412/2000000 [00:01<00:01, 921227.13it/s]\u001b[A\n",
            " 51%|█████     | 1022566/2000000 [00:01<00:01, 924348.47it/s]\u001b[A\n",
            " 56%|█████▌    | 1117270/2000000 [00:01<00:00, 931200.62it/s]\u001b[A\n",
            " 61%|██████    | 1210775/2000000 [00:01<00:00, 932346.40it/s]\u001b[A\n",
            " 65%|██████▌   | 1306319/2000000 [00:01<00:00, 939293.17it/s]\u001b[A\n",
            " 70%|███████   | 1403104/2000000 [00:01<00:00, 947871.77it/s]\u001b[A\n",
            " 75%|███████▍  | 1497907/2000000 [00:01<00:00, 898704.60it/s]\u001b[A\n",
            " 80%|███████▉  | 1590723/2000000 [00:01<00:00, 907211.56it/s]\u001b[A\n",
            " 84%|████████▍ | 1681852/2000000 [00:01<00:00, 900678.25it/s]\u001b[A\n",
            " 89%|████████▉ | 1779499/2000000 [00:01<00:00, 922871.22it/s]\u001b[A\n",
            " 94%|█████████▎| 1872039/2000000 [00:02<00:00, 912538.71it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 918825.14it/s]\n",
            "M/G/1 Experiments:  25%|██▌       | 2/8 [00:14<00:41,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 48133/2000000 [00:00<00:04, 481259.32it/s]\u001b[A\n",
            "  5%|▌         | 101547/2000000 [00:00<00:03, 512344.61it/s]\u001b[A\n",
            "  9%|▉         | 185880/2000000 [00:00<00:02, 663458.75it/s]\u001b[A\n",
            " 13%|█▎        | 260142/2000000 [00:00<00:02, 694697.19it/s]\u001b[A\n",
            " 18%|█▊        | 358375/2000000 [00:00<00:02, 798397.35it/s]\u001b[A\n",
            " 23%|██▎       | 455554/2000000 [00:00<00:01, 857330.78it/s]\u001b[A\n",
            " 27%|██▋       | 548442/2000000 [00:00<00:01, 880705.42it/s]\u001b[A\n",
            " 32%|███▏      | 646423/2000000 [00:00<00:01, 912234.53it/s]\u001b[A\n",
            " 37%|███▋      | 745745/2000000 [00:00<00:01, 937532.84it/s]\u001b[A\n",
            " 42%|████▏     | 845062/2000000 [00:01<00:01, 954694.67it/s]\u001b[A\n",
            " 47%|████▋     | 945963/2000000 [00:01<00:01, 971302.71it/s]\u001b[A\n",
            " 52%|█████▏    | 1043094/2000000 [00:01<00:01, 955402.64it/s]\u001b[A\n",
            " 57%|█████▋    | 1140795/2000000 [00:01<00:00, 961857.50it/s]\u001b[A\n",
            " 62%|██████▏   | 1237029/2000000 [00:01<00:00, 918226.86it/s]\u001b[A\n",
            " 67%|██████▋   | 1336554/2000000 [00:01<00:00, 940553.72it/s]\u001b[A\n",
            " 72%|███████▏  | 1434351/2000000 [00:01<00:00, 951500.82it/s]\u001b[A\n",
            " 77%|███████▋  | 1530732/2000000 [00:01<00:00, 955116.58it/s]\u001b[A\n",
            " 82%|████████▏ | 1631476/2000000 [00:01<00:00, 970615.79it/s]\u001b[A\n",
            " 86%|████████▋ | 1729718/2000000 [00:01<00:00, 974112.40it/s]\u001b[A\n",
            " 92%|█████████▏| 1830195/2000000 [00:02<00:00, 983238.75it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 908506.65it/s]\n",
            "M/G/1 Experiments:  38%|███▊      | 3/8 [00:21<00:36,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 90985/2000000 [00:00<00:02, 909785.79it/s]\u001b[A\n",
            "  9%|▉         | 181964/2000000 [00:00<00:02, 864376.56it/s]\u001b[A\n",
            " 14%|█▎        | 274149/2000000 [00:00<00:01, 889875.70it/s]\u001b[A\n",
            " 19%|█▊        | 373308/2000000 [00:00<00:01, 929333.42it/s]\u001b[A\n",
            " 24%|██▎       | 473320/2000000 [00:00<00:01, 954561.72it/s]\u001b[A\n",
            " 29%|██▊       | 572857/2000000 [00:00<00:01, 968318.92it/s]\u001b[A\n",
            " 34%|███▎      | 672049/2000000 [00:00<00:01, 975978.13it/s]\u001b[A\n",
            " 38%|███▊      | 769716/2000000 [00:00<00:01, 973994.96it/s]\u001b[A\n",
            " 43%|████▎     | 867163/2000000 [00:00<00:01, 972312.46it/s]\u001b[A\n",
            " 48%|████▊     | 964427/2000000 [00:01<00:01, 961413.13it/s]\u001b[A\n",
            " 53%|█████▎    | 1063682/2000000 [00:01<00:00, 970824.81it/s]\u001b[A\n",
            " 58%|█████▊    | 1160807/2000000 [00:01<00:00, 965315.46it/s]\u001b[A\n",
            " 63%|██████▎   | 1257371/2000000 [00:01<00:00, 925922.28it/s]\u001b[A\n",
            " 68%|██████▊   | 1356062/2000000 [00:01<00:00, 943681.14it/s]\u001b[A\n",
            " 73%|███████▎  | 1455239/2000000 [00:01<00:00, 957799.08it/s]\u001b[A\n",
            " 78%|███████▊  | 1552544/2000000 [00:01<00:00, 962293.70it/s]\u001b[A\n",
            " 83%|████████▎ | 1650692/2000000 [00:01<00:00, 967972.15it/s]\u001b[A\n",
            " 87%|████████▋ | 1747621/2000000 [00:01<00:00, 947849.68it/s]\u001b[A\n",
            " 92%|█████████▏| 1842577/2000000 [00:01<00:00, 945481.42it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 952818.24it/s]\n",
            "M/G/1 Experiments:  50%|█████     | 4/8 [00:28<00:27,  6.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 92936/2000000 [00:00<00:02, 929281.13it/s]\u001b[A\n",
            "  9%|▉         | 188889/2000000 [00:00<00:01, 947046.60it/s]\u001b[A\n",
            " 14%|█▍        | 286041/2000000 [00:00<00:01, 958197.71it/s]\u001b[A\n",
            " 19%|█▉        | 381861/2000000 [00:00<00:01, 947859.06it/s]\u001b[A\n",
            " 24%|██▍       | 481281/2000000 [00:00<00:01, 964424.50it/s]\u001b[A\n",
            " 29%|██▉       | 581699/2000000 [00:00<00:01, 977862.73it/s]\u001b[A\n",
            " 34%|███▍      | 679507/2000000 [00:00<00:01, 971911.98it/s]\u001b[A\n",
            " 39%|███▉      | 779950/2000000 [00:00<00:01, 982144.10it/s]\u001b[A\n",
            " 44%|████▍     | 878185/2000000 [00:00<00:01, 784180.62it/s]\u001b[A\n",
            " 48%|████▊     | 962664/2000000 [00:01<00:01, 565940.84it/s]\u001b[A\n",
            " 53%|█████▎    | 1050851/2000000 [00:01<00:01, 632063.11it/s]\u001b[A\n",
            " 57%|█████▋    | 1147422/2000000 [00:01<00:01, 708855.13it/s]\u001b[A\n",
            " 62%|██████▏   | 1244546/2000000 [00:01<00:00, 773771.07it/s]\u001b[A\n",
            " 67%|██████▋   | 1337424/2000000 [00:01<00:00, 814245.54it/s]\u001b[A\n",
            " 72%|███████▏  | 1433791/2000000 [00:01<00:00, 854834.89it/s]\u001b[A\n",
            " 77%|███████▋  | 1532121/2000000 [00:01<00:00, 890739.60it/s]\u001b[A\n",
            " 82%|████████▏ | 1630492/2000000 [00:01<00:00, 917259.34it/s]\u001b[A\n",
            " 87%|████████▋ | 1730855/2000000 [00:02<00:00, 942259.02it/s]\u001b[A\n",
            " 91%|█████████▏| 1827156/2000000 [00:02<00:00, 911753.11it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 854847.65it/s]\n",
            "M/G/1 Experiments:  62%|██████▎   | 5/8 [00:36<00:21,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 91558/2000000 [00:00<00:02, 915412.82it/s]\u001b[A\n",
            "  9%|▉         | 186909/2000000 [00:00<00:01, 937774.42it/s]\u001b[A\n",
            " 14%|█▍        | 286291/2000000 [00:00<00:01, 963340.57it/s]\u001b[A\n",
            " 19%|█▉        | 385184/2000000 [00:00<00:01, 973428.13it/s]\u001b[A\n",
            " 24%|██▍       | 484971/2000000 [00:00<00:01, 982225.10it/s]\u001b[A\n",
            " 29%|██▉       | 585353/2000000 [00:00<00:01, 989547.35it/s]\u001b[A\n",
            " 34%|███▍      | 684308/2000000 [00:00<00:01, 920687.84it/s]\u001b[A\n",
            " 39%|███▉      | 779032/2000000 [00:00<00:01, 928716.70it/s]\u001b[A\n",
            " 44%|████▍     | 876685/2000000 [00:00<00:01, 943137.24it/s]\u001b[A\n",
            " 49%|████▉     | 975555/2000000 [00:01<00:01, 956852.61it/s]\u001b[A\n",
            " 54%|█████▎    | 1071608/2000000 [00:01<00:00, 957501.41it/s]\u001b[A\n",
            " 58%|█████▊    | 1167614/2000000 [00:01<00:00, 957371.97it/s]\u001b[A\n",
            " 63%|██████▎   | 1264454/2000000 [00:01<00:00, 960672.68it/s]\u001b[A\n",
            " 68%|██████▊   | 1364138/2000000 [00:01<00:00, 971515.93it/s]\u001b[A\n",
            " 73%|███████▎  | 1462716/2000000 [00:01<00:00, 975775.90it/s]\u001b[A\n",
            " 78%|███████▊  | 1561069/2000000 [00:01<00:00, 978067.23it/s]\u001b[A\n",
            " 83%|████████▎ | 1658925/2000000 [00:01<00:00, 923816.25it/s]\u001b[A\n",
            " 88%|████████▊ | 1752509/2000000 [00:01<00:00, 927262.67it/s]\u001b[A\n",
            " 93%|█████████▎| 1851801/2000000 [00:01<00:00, 946392.91it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 951598.37it/s]\n",
            "M/G/1 Experiments:  75%|███████▌  | 6/8 [00:42<00:13,  6.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 88257/2000000 [00:00<00:02, 882501.41it/s]\u001b[A\n",
            "  9%|▉         | 176508/2000000 [00:00<00:02, 871962.27it/s]\u001b[A\n",
            " 13%|█▎        | 265260/2000000 [00:00<00:01, 878997.32it/s]\u001b[A\n",
            " 18%|█▊        | 358475/2000000 [00:00<00:01, 899881.21it/s]\u001b[A\n",
            " 22%|██▏       | 448478/2000000 [00:00<00:01, 863396.74it/s]\u001b[A\n",
            " 27%|██▋       | 536242/2000000 [00:00<00:01, 868087.07it/s]\u001b[A\n",
            " 32%|███▏      | 630885/2000000 [00:00<00:01, 893179.55it/s]\u001b[A\n",
            " 36%|███▋      | 726755/2000000 [00:00<00:01, 913737.07it/s]\u001b[A\n",
            " 41%|████      | 821885/2000000 [00:00<00:01, 925354.38it/s]\u001b[A\n",
            " 46%|████▌     | 914530/2000000 [00:01<00:01, 923159.10it/s]\u001b[A\n",
            " 51%|█████     | 1010782/2000000 [00:01<00:01, 935063.78it/s]\u001b[A\n",
            " 55%|█████▌    | 1104349/2000000 [00:01<00:00, 930488.32it/s]\u001b[A\n",
            " 60%|█████▉    | 1199039/2000000 [00:01<00:00, 935414.26it/s]\u001b[A\n",
            " 65%|██████▍   | 1292615/2000000 [00:01<00:00, 930778.38it/s]\u001b[A\n",
            " 69%|██████▉   | 1385721/2000000 [00:01<00:00, 886816.90it/s]\u001b[A\n",
            " 74%|███████▍  | 1481664/2000000 [00:01<00:00, 907811.12it/s]\u001b[A\n",
            " 79%|███████▉  | 1578514/2000000 [00:01<00:00, 925549.74it/s]\u001b[A\n",
            " 84%|████████▎ | 1674831/2000000 [00:01<00:00, 936614.20it/s]\u001b[A\n",
            " 88%|████████▊ | 1768737/2000000 [00:01<00:00, 936371.40it/s]\u001b[A\n",
            " 93%|█████████▎| 1863593/2000000 [00:02<00:00, 939980.61it/s]\u001b[A\n",
            "100%|██████████| 2000000/2000000 [00:02<00:00, 914750.32it/s]\n",
            "M/G/1 Experiments:  88%|████████▊ | 7/8 [00:50<00:07,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting M/G/1 simulation with 2000000 customers...\n",
            "Processing customers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 92720/2000000 [00:00<00:02, 927134.57it/s]\u001b[A\n",
            "  9%|▉         | 185455/2000000 [00:00<00:01, 927235.80it/s]\u001b[A\n",
            " 14%|█▍        | 282602/2000000 [00:00<00:01, 947402.92it/s]\u001b[A\n",
            " 19%|█▉        | 377343/2000000 [00:00<00:01, 901521.25it/s]\u001b[A\n",
            " 24%|██▍       | 475129/2000000 [00:00<00:01, 928163.04it/s]\u001b[A\n",
            " 29%|██▊       | 572815/2000000 [00:00<00:01, 944354.49it/s]\u001b[A\n",
            " 33%|███▎      | 667477/2000000 [00:00<00:01, 939544.53it/s]\u001b[A\n",
            " 38%|███▊      | 761583/2000000 [00:00<00:01, 931956.71it/s]\u001b[A\n",
            " 43%|████▎     | 854886/2000000 [00:00<00:01, 930584.13it/s]\u001b[A\n",
            " 48%|████▊     | 952188/2000000 [00:01<00:01, 943514.40it/s]\u001b[A\n",
            " 52%|█████▏    | 1048103/2000000 [00:01<00:01, 948242.98it/s]\u001b[A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjJg6oG1VD2p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}